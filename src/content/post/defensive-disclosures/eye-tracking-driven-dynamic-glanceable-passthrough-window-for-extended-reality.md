---
title: Eye Tracking Driven Dynamic Glanceable Passthrough Window for Extended Reality
excerpt: Virtual reality (VR) and extended reality (XR) devices offer an immersive experience to users. However, such an immersive experience can create a disconnect from the real world for users.
sectiontype: disclosure
publishDate: 2024-11-28
disclosureId: DD20241129001
# patentId: US11880882B2
metadata:
  title: Method for Secure Blockchain-Based Voting
  description: A transparent and secure voting system leveraging blockchain technology to ensure election integrity.
  robots:
    index: false
    follow: false
  openGraph:
    title: Secure Blockchain-Based Voting | IntellectualFrontiers
    description: A transparent and secure voting system leveraging blockchain technology to ensure election integrity.
    images:
      - url: '/images/disclosures/blockchain-voting/blockchain-voting-disclosure.webp'
        width: 1200
        height: 628
    type: website
  twitter:
    cardType: summary_large_image
submissionDate: 2024-11-10
url: '/defensive-disclosures/secure-blockchain-voting'
category: "Defensive Disclosure"
abstract: A system for conducting anonymous voting using blockchain to ensure voter privacy and election transparency.
problemSolved: Eliminates the risk of tampering and fraud in digital voting systems while maintaining voter anonymity.
disclosureAuthors:
    - Kathleen Bryan
    - Shiblee Hasan
image: 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcREO3tkIJnmJZcWmgLLR-z973QVHQ8zbwDGnw&s'
# tags:
#   - Virtual Reality
#   - Extended Reality
downloadableDocument: 'https://example.com/blockchain-voting-disclosure.pdf'
---
## Abstract

Virtual reality (VR) and extended reality (XR) devices offer an immersive experience to users. However, such an immersive experience can create a disconnect from the real world for users. Events or distractions in the physical world around the user can necessitate a rapid context switch between the virtual and physical environment. This disclosure describes techniques that enable temporary access to real world visuals for users wearing a VR/XR device without the user having to remove VR/XR devices and with minimal disruption of the digital immersion experience. With user permission, the device performs eye tracking to obtain precise understanding of direction of a user's gaze and focus, including rapid shifts in attention. The techniques described herein use the eye tracking mechanism to detect when an event in the real world occurs that the user turns their attention to and in real time, automatically generates a dynamic window within a digital immersive environment that displays the physical environment in the direction of the user’s gaze.

## Keywords

- Extended reality (XR)
- Virtual reality (VR)
- Augmented reality (AR)
- Glanceable window
- Passthrough
- Eye tracking
- Immersive experience

## Background

Virtual reality (VR) and extended reality (XR) devices offer an immersive experience to users. However, such an immersive experience can create a disconnect from the real world for users. Events or distractions in the physical world around the user can necessitate a rapid context switch between the virtual and physical environment. To address interruptions, users may have to remove the VR/XR device or temporarily disconnect from the immersive experience to connect with the physical environment. Such interruptions can lead to a suboptimal user experience. 

## Description

This disclosure describes techniques that enable temporary access to real world visuals for users wearing a VR/XR device (headset) without the user having to remove VR/XR devices and with minimal disruption of the digital immersion experience. With user permission, the device performs eye tracking to obtain precise understanding of direction of a user's gaze and focus, including rapid shifts in attention. Passthrough is the ability to view the real world environment through the VR/XR device without taking off the device. The techniques described herein use the eye tracking mechanism coupled with passthrough to automatically generate a dynamic window to the physical environment within a digital immersive environment. The window is generated based on detecting events in the physical environment that likely demand the user’s attention.

<img src="/images/disclosure/eye-tracking-driven-dynamic-glanceable-passthrough-window-for-extended-reality-1.png" class="!shadow-none" alt="fig-1a"/>

<img src="/images/disclosure/eye-tracking-driven-dynamic-glanceable-passthrough-window-for-extended-reality-2.png" class="!shadow-none !mb-0" alt="fig-2a"/>

<div class="flex mx-auto items-center justify-center">
<div class="font-bold">
Fig. 1: Dynamic glanceable passthrough window generation
</div>
</div>

Fig. 1 illustrates an example of generating dynamic glanceable passthrough window using eye tracking techniques while a user participates in an immersive experience using a VR/XR device. As depicted in Fig. 1(a), a user wearing a VR/XR headset (102) is experiencing immersive content (106) through the headset. An event or activity (104) occurs in the real world that is determined as likely requiring the user’s attention. In the example of Fig. 1(a), another person in the vicinity of the user (from the real environment) has called out to the user, asking a question, “Hey John! Want some coffee?”.

Upon hearing a question directed at them, the user reacts to the question by instinctively glancing in the direction of the voice. Based on detecting this eye movement via eye tracking, the direction of the user's gaze is determined. Without interrupting the digital content being displayed by the headset, a passthrough window (108) is generated in real-time as depicted in Fig.1(b). As seen in the figure, the window is aligned to the user's gaze and provides visuals from the physical environment.  

A real world window that is minimally disruptive of an immersive experience and is automatically provided upon detection of real world events by rapid changes in the user’s gaze can help enhance situational awareness while participating in VR/XR experiences. The described techniques can be implemented in the headset operating system or other software and can also be made available to developers via an application programming interface (API).

Further to the descriptions above, a user is provided with controls allowing the user to make an election as to both if and when systems, programs or features described herein may enable collection of user information (e.g., information about a user’s eye gaze, a user’s surroundings, a user’s preferences, or a user’s current location), and if the user is sent content or communications from a server. In addition, certain data are treated in one or more ways before it is stored or used, so that personally identifiable information is removed. For example, a user’s identity may be treated so that no personally identifiable information can be determined for the user, or a user’s geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined. Thus, the user has control over what information is collected about the user, how that information is used, and what information is provided to the user.

## Conclusion

This disclosure describes techniques that enable temporary access to real world visuals for users wearing a VR/XR device without the user having to remove VR/XR devices and with minimal disruption of the digital immersion experience. With user permission, the device performs eye tracking to obtain precise understanding of direction of a user's gaze and focus, including rapid shifts in attention. The techniques described herein use the eye tracking mechanism to detect when an event in the real world occurs that the user turns their attention to and in real time, automatically generates a dynamic window within a digital immersive environment that displays the physical environment in the direction of the user’s gaze.

## References

1. Rahman, Sazzadur, Konstantine Nicholas John Tsotsos, João Manuel de Castro Afonso, José Carlos Maranhão Pascoal, Ivo Duarte, and Nuno Cruces. "Eye image stabilized augmented reality displays." U.S. Patent 11,681,358, issued June 20, 2023.
